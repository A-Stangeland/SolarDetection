{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.layers import Conv2D, MaxPool2D, UpSampling2D, Concatenate, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "tf.config.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.permutation(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (128, 128, 3)\n",
    "\n",
    "conv_args = dict(kernel_size=(3,3), padding=\"same\", activation=\"relu\")\n",
    "\n",
    "in_unet = Input(input_shape)\n",
    "x = Conv2D(32, **conv_args)(in_unet)\n",
    "x1 = Conv2D(32, **conv_args)(x)\n",
    "x = MaxPool2D()(x1)\n",
    "\n",
    "x = Conv2D(64, **conv_args)(x)\n",
    "x2 = Conv2D(64, **conv_args)(x)\n",
    "x = MaxPool2D()(x2)\n",
    "\n",
    "x = Conv2D(128, **conv_args)(x)\n",
    "x3 = Conv2D(128, **conv_args)(x)\n",
    "x = MaxPool2D()(x3)\n",
    "\n",
    "x = Conv2D(256, **conv_args)(x)\n",
    "x = Conv2D(256, **conv_args)(x)\n",
    "\n",
    "x = UpSampling2D()(x)\n",
    "x = Concatenate(axis=-1)([x, x3])\n",
    "x = Conv2D(128, **conv_args)(x)\n",
    "x = Conv2D(128, **conv_args)(x)\n",
    "\n",
    "x = UpSampling2D()(x)\n",
    "x = Concatenate(axis=-1)([x, x2])\n",
    "x = Conv2D(64, **conv_args)(x)\n",
    "x = Conv2D(64, **conv_args)(x)\n",
    "\n",
    "x = UpSampling2D()(x)\n",
    "x = Concatenate(axis=-1)([x, x1])\n",
    "x = Conv2D(32, **conv_args)(x)\n",
    "x = Conv2D(32, **conv_args)(x)\n",
    "\n",
    "out_unet = Conv2D(1, kernel_size=(3,3), padding=\"same\", activation=\"sigmoid\")(x)\n",
    "\n",
    "unet = Model(in_unet, out_unet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.compile(loss=\"binary_crossentropy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import ImageStream\n",
    "\n",
    "train_gen = ImageStream(\"mask_dataset/train\")\n",
    "\n",
    "img, mask = train_gen.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "seed = 1\n",
    "train_img_generator = train_datagen.flow_from_directory(\n",
    "        \"mask_dataset/train\",\n",
    "        color_mode=\"rgb\",\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        classes=[\"image\"],\n",
    "        seed=seed)\n",
    "\n",
    "train_mask_generator = train_datagen.flow_from_directory(\n",
    "        'mask_dataset/train/',\n",
    "        target_size=(128, 128),\n",
    "        batch_size=32,\n",
    "        shuffle=True,\n",
    "        classes=[\"label\"],\n",
    "        seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = train_img_generator.next()\n",
    "mask = train_mask_generator.next()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 4, 4\n",
    "fig, ax = plt.subplots(h, w, figsize=(12,12))\n",
    "\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        ax[i,j].imshow(img[0][w*i+j])\n",
    "        ax[i,j].imshow(np.ma.masked_equal(mask[0][w*i+j], 0), alpha=.5)\n",
    "        ax[i,j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import ImageStream\n",
    "\n",
    "train_gen = ImageStream(\"test_dataset/train\")\n",
    "X, y = train_gen.load_dataset(1000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.fit(X, y, batch_size=20, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet = keras.models.load_model(\"trained_models/Unet/unet_v1.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image, mask = train_gen.next()\n",
    "mask_pred = unet.predict(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageStream(\"test_dataset/test\")\n",
    "X_test, y_test = train_gen.load_dataset(2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(mask_pred[w*i+j,:,:,0] > .5).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w, h = 4, 4\n",
    "fig, ax = plt.subplots(h, w, figsize=(12,12))\n",
    "\n",
    "for i in range(h):\n",
    "    for j in range(w):\n",
    "        ax[i,j].imshow(image[w*i+j])\n",
    "        # ax[i,j].imshow(mask[w*i+j,:,:,0], cmap=\"gray\")\n",
    "        ax[i,j].imshow(np.ma.masked_less(mask_pred[w*i+j,:,:,0], .5), alpha=.5)\n",
    "        ax[i,j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.save(r\"trained_models\\Unet\\unet_v1.tf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 1\n",
    "image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    'mask_dataset/train',\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=[\"image\"],\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    'mask_dataset/train',\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=[\"label\"],\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_generator.next().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    'mask_dataset/train',\n",
    "    target_size=(128,128),\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=[\"image\"],\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    'mask_dataset/train',\n",
    "    target_size=(128,128),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=[\"label\"],\n",
    "    seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_generation import SegmentationDataGenerator\n",
    "\n",
    "data_denerator = SegmentationDataGenerator(\"test_dataset/train\", \"test_dataset/train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unet.fit(\n",
    "    data_denerator,\n",
    "    steps_per_epoch=400,\n",
    "    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# data_gen_args = dict(featurewise_center=True,\n",
    "#                      featurewise_std_normalization=True,\n",
    "#                      rotation_range=90,\n",
    "#                      width_shift_range=0.1,\n",
    "#                      height_shift_range=0.1,\n",
    "#                      zoom_range=0.2)\n",
    "\n",
    "# image_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# mask_datagen = ImageDataGenerator(**data_gen_args)\n",
    "# # Provide the same seed and keyword arguments to the fit and flow methods\n",
    "\n",
    "# seed = 1\n",
    "# image_datagen.fit(images, augment=True, seed=seed)\n",
    "# mask_datagen.fit(masks, augment=True, seed=seed)\n",
    "\n",
    "seed = 1\n",
    "image_datagen = ImageDataGenerator(rescale=1./255)\n",
    "mask_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "image_generator = image_datagen.flow_from_directory(\n",
    "    'mask_dataset/train',\n",
    "    target_size=(128,128),\n",
    "    color_mode=\"rgb\",\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=[\"image\"],\n",
    "    seed=seed)\n",
    "\n",
    "mask_generator = mask_datagen.flow_from_directory(\n",
    "    'mask_dataset/train',\n",
    "    target_size=(128,128),\n",
    "    color_mode=\"grayscale\",\n",
    "    class_mode=None,\n",
    "    shuffle=False,\n",
    "    classes=[\"label\"],\n",
    "    seed=seed)\n",
    "\n",
    "\n",
    "\n",
    "# combine generators into one which yields image and masks\n",
    "train_generator = zip(train_img_generator, train_mask_generator)\n",
    "unet.fit(\n",
    "    train_generator,\n",
    "    # steps_per_epoch=400,\n",
    "    epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import Sequence\n",
    "\n",
    "class DataGenerator(Sequence):\n",
    "    'Generates data for Keras'\n",
    "    \n",
    "    def __init__(self, pair, class_map, batch_size=16, dim=(224,224,3), shuffle=True):\n",
    "        'Initialization'\n",
    "        self.dim = dim\n",
    "        self.pair = pair\n",
    "        self.class_map = class_map\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        'Denotes the number of batches per epoch'\n",
    "        return len(self.pair) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        'Generate one batch of data'\n",
    "        # Generate indexes of the batch\n",
    "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
    "\n",
    "        # Find list of IDs\n",
    "        list_IDs_temp = [k for k in indexes]\n",
    "\n",
    "        # Generate data\n",
    "        X, y = self.__data_generation(list_IDs_temp)\n",
    "\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        'Updates indexes after each epoch'\n",
    "        self.indexes = np.arange(len(self.pair))\n",
    "        if self.shuffle == True:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, list_IDs_temp):\n",
    "        'Generates data containing batch_size samples' # X : (n_samples, *dim, n_channels)\n",
    "        # Initialization\n",
    "        batch_imgs = list()\n",
    "        batch_labels = list()\n",
    "\n",
    "        # Generate data\n",
    "        for i in list_IDs_temp:\n",
    "            # Store sample\n",
    "            img = load_img(self.pair[i][0] ,target_size=self.dim)\n",
    "            img = img_to_array(img)/255.\n",
    "            batch_imgs.append(img)\n",
    "\n",
    "            label = load_img(self.pair[i][1],target_size=self.dim)\n",
    "            label = img_to_array(label)\n",
    "            label = form_2D_label(label,self.class_map)\n",
    "            label = to_categorical(label , num_classes = 32)\n",
    "            batch_labels.append(label)\n",
    "            \n",
    "        return np.array(batch_imgs) ,np.array(batch_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8fdb4faa7bb0879793b86fd6100323c1b63f0e6755fa877c915901b363e7641f"
  },
  "kernelspec": {
   "display_name": "Python 3.6.13 64-bit ('projet': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
